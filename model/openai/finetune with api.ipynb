{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17548,"status":"ok","timestamp":1708328144100,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"8j-0FQqeXT0b","outputId":"8bf90a40-1840-450d-dedf-55fc73cd7b77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'openai-cookbook'...\n","remote: Enumerating objects: 5265, done.\u001b[K\n","remote: Counting objects: 100% (1059/1059), done.\u001b[K\n","remote: Compressing objects: 100% (765/765), done.\u001b[K\n","remote: Total 5265 (delta 308), reused 1037 (delta 294), pack-reused 4206\u001b[K\n","Receiving objects: 100% (5265/5265), 240.73 MiB | 18.41 MiB/s, done.\n","Resolving deltas: 100% (2809/2809), done.\n","Updating files: 100% (1274/1274), done.\n"]}],"source":["# è¤‡è£½openaiä½¿ç”¨æ•™å­¸\n","!git clone https://github.com/openai/openai-cookbook.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32244,"status":"ok","timestamp":1708329031341,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"egh99ctRT1VK","outputId":"292e3b74-f29b-4e50-e4b4-93932538bc9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai==1.6.1\n","  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/225.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.6/225.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.6.1) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai==1.6.1)\n","  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (2.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (4.9.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.6.1) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.6.1) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.6.1) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.6.1)\n","  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.6.1)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.6.1) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.6.1) (2.16.2)\n","Installing collected packages: h11, httpcore, httpx, openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.6.1\n","Collecting tiktoken\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Installing collected packages: tiktoken\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tiktoken-0.6.0\n","Collecting datasets\n","  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Collecting pyarrow>=12.0.0 (from datasets)\n","  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 10.0.1\n","    Uninstalling pyarrow-10.0.1:\n","      Successfully uninstalled pyarrow-10.0.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.17.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-15.0.0\n"]}],"source":["# ä¸‹è¼‰æœ€æ–°ç‰ˆçš„openaiå¥—ä»¶\n","!pip install openai==1.6.1  # origin using 1.12\n","# ä¸‹è¼‰tokenè¨ˆç®—å¥—ä»¶\n","!pip install tiktoken\n","!pip install datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2583,"status":"ok","timestamp":1708329162061,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"-KCqzNlWvQg6"},"outputs":[],"source":["import openai\n","import json\n","# for token counting\n","import tiktoken\n","import numpy as np\n","from collections import defaultdict\n","from datasets import load_dataset\n","# drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708329931716,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"BaBdPYlBwM_J","outputId":"b497afed-53b3-48ae-cab7-793d9c80aae2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Num examples: 1783\n","First example:\n","{'role': 'system', 'content': 'æ³•æ¢ç´¢å¼•'}\n","{'role': 'user', 'content': 'å…¬å¸æ³•ç¬¬ 340 æ¢?'}\n","{'role': 'assistant', 'content': 'å…¬å¸å°æ–¼å…¶å‚µå‹™ä¹‹æ¸…å„Ÿï¼Œæ‡‰ä¾å…¶å‚µæ¬Šé¡æ¯”ä¾‹ç‚ºä¹‹ã€‚ä½†ä¾æ³•å¾—è¡Œä½¿å„ªå…ˆå—å„Ÿæ¬Šæˆ–åˆ¥é™¤æ¬Šä¹‹å‚µæ¬Šï¼Œä¸åœ¨æ­¤é™ã€‚ '}\n"]}],"source":["data_path = \"\"  #/toy_chat_fine_tuning.jsonl\n","\n","# Load the dataset\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    dataset = [json.loads(line) for line in f]\n","\n","# Initial dataset stats\n","print(\"Num examples:\", len(dataset))\n","print(\"First example:\")\n","for message in dataset[0][\"messages\"]:\n","    print(message)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708329934597,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"uh293sn_yTlQ","outputId":"c0bfd088-0f02-48cf-9642-9d64d599919b"},"outputs":[{"name":"stdout","output_type":"stream","text":["No errors found\n"]}],"source":["# æª¢æŸ¥è³‡æ–™æ ¼å¼æ˜¯å¦ç¬¦åˆopenaiå®˜æ–¹è¨­å®š\n","format_errors = defaultdict(int)\n","\n","for ex in dataset:\n","    if not isinstance(ex, dict):\n","        format_errors[\"data_type\"] += 1\n","        continue\n","\n","    messages = ex.get(\"messages\", None)\n","    if not messages:\n","        format_errors[\"missing_messages_list\"] += 1\n","        continue\n","\n","    for message in messages:\n","        if \"role\" not in message or \"content\" not in message:\n","            format_errors[\"message_missing_key\"] += 1\n","\n","        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n","            format_errors[\"message_unrecognized_key\"] += 1\n","\n","        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n","            format_errors[\"unrecognized_role\"] += 1\n","\n","        content = message.get(\"content\", None)\n","        function_call = message.get(\"function_call\", None)\n","\n","        if (not content and not function_call) or not isinstance(content, str):\n","            format_errors[\"missing_content\"] += 1\n","\n","    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","        format_errors[\"example_missing_assistant_message\"] += 1\n","\n","if format_errors:\n","    print(\"Found errors:\")\n","    for k, v in format_errors.items():\n","        print(f\"{k}: {v}\")\n","else:\n","    print(\"No errors found\")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2157,"status":"ok","timestamp":1708329945903,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"2SgMumGfzMjM"},"outputs":[],"source":["# æ•¸è¨“ç·´è³‡æ–™ä¸­ä¸­åŒ…å«å¹¾å€‹token\n","encoding = tiktoken.get_encoding(\"cl100k_base\")  #tiktoken is a fast BPE tokeniser for use with OpenAI's models.\n","\n","# not exact!\n","# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n","def num_tokens_from_messages(instruction, tokens_per_message=3, tokens_per_name=1):\n","    num_tokens = 0\n","    for message in messages:\n","        num_tokens += tokens_per_message\n","        for key, value in message.items():\n","            num_tokens += len(encoding.encode(value))\n","            if key == \"name\":\n","                num_tokens += tokens_per_name\n","    num_tokens += 3\n","    return num_tokens\n","\n","def num_assistant_tokens_from_messages(messages):\n","    num_tokens = 0\n","    for message in messages:\n","        if message[\"role\"] == \"assistant\":\n","            num_tokens += len(encoding.encode(message[\"content\"]))\n","    return num_tokens\n","\n","def print_distribution(values, name):\n","    print(f\"\\n#### Distribution of {name}:\")\n","    print(f\"min / max: {min(values)}, {max(values)}\")\n","    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n","    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708329962298,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"k2jIwNyNUIw7","outputId":"f63a41bc-d62b-4525-a880-d316e60b659f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset has ~5349 tokens that will be charged for during training\n","By default, you'll train for 3 epochs on this dataset\n","By default, you'll be charged for ~16047 tokens\n"]}],"source":["# é è¨ˆè¨“ç·´æ¬¡æ•¸å’Œåƒ¹æ ¼\n","MAX_TOKENS_PER_EXAMPLE = 4096\n","\n","TARGET_EPOCHS = 3\n","MIN_TARGET_EXAMPLES = 100\n","MAX_TARGET_EXAMPLES = 25000\n","MIN_DEFAULT_EPOCHS = 1\n","MAX_DEFAULT_EPOCHS = 25\n","\n","n_epochs = TARGET_EPOCHS\n","n_train_examples = len(dataset)\n","if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n","    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n","elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n","    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n","\n","convo_lens = [len(conversation['messages']) for conversation in dataset]\n","n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n","print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n","print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n","print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_gAl86dbrZk"},"outputs":[],"source":["training_file = \"\"\n","validation_file = \"\""]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2250,"status":"ok","timestamp":1708330011531,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"6ehkrpKiMazZ","outputId":"72b5a072-5be2-4961-bb23-0003e47c649c"},"outputs":[{"data":{"text/plain":["FileObject(id='file-yI9mGxdfZnFY8IK6avk0z8kX', bytes=814479, created_at=1708330010, filename='remain_lawdata.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# ä¸Šå‚³è¨“ç·´è³‡æ–™\n","\n","\n","from openai import OpenAI  #for verion 1.12\n","client = OpenAI(api_key=\"\")\n","\n","client.files.create(\n","  file=open(\"\" , \"rb\"),\n","  purpose=\"fine-tune\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1214,"status":"ok","timestamp":1708017588811,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"iTbTdQbBOTKp","outputId":"81b4463d-2216-4f53-82fe-3867710f7d1c"},"outputs":[{"data":{"text/plain":["FileObject(id='file-ZVCGTcNrMzYDBHVYyfBc1PlB', bytes=238352, created_at=1708017588, filename='test-api.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["from openai import OpenAI\n","client = OpenAI(api_key=\"\")\n","\n","client.files.create(\n","  file=open(validation_file, \"rb\"),\n","  purpose=\"fine-tune\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":11,"status":"error","timestamp":1708011940014,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"SeWC330POujB","outputId":"64f3811d-643b-4846-b6c1-9499ef70a122"},"outputs":[{"ename":"AttributeError","evalue":"type object 'OpenAI' has no attribute 'file'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-aaff661ca260>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mOpenAI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file-zNnRhfyCXhtSq1lVtRVVylx6\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#trace the file status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: type object 'OpenAI' has no attribute 'file'"]}],"source":["# OpenAI.file.retrieve(\"file-zNnRhfyCXhtSq1lVtRVVylx6\")  #trace the file status"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708330902535,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"29X2aqBc_77Q","outputId":"b6aaa456-0e64-4351-e486-e3a4d7f00cba"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m10622130\u001b[0m (\u001b[33mtw-nlp-law\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# !pip install wandb  #sync the traning data with wandb\n","import wandb\n","wandb.login()\n","# !pip install requests"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":710,"status":"error","timestamp":1708330972332,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"nqJo0QC7SiDM","outputId":"d71c0e04-ac62-4ab3-b653-1afe64f7398f"},"outputs":[{"ename":"BadRequestError","evalue":"Error code: 400 - {'error': {'message': 'invalid training_file: /content/remain_lawdata.jsonl', 'type': 'invalid_request_error', 'param': 'training_file', 'code': None}}","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-93351a628b3b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"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\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m response = client.fine_tuning.jobs.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtraining_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/remain_lawdata.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/fine_tuning/jobs.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, training_file, hyperparameters, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;34m\"/fine_tuning/jobs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         )\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 853\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         return self._process_response(\n","\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'invalid training_file: /content/remain_lawdata.jsonl', 'type': 'invalid_request_error', 'param': 'training_file', 'code': None}}"]}],"source":["# å»ºç«‹ä¸¦åŸ·è¡Œfinetuneä»»å‹™\n","from openai import OpenAI\n","from openai.types.fine_tuning import FineTuningJob, FineTuningJobEvent\n","client = OpenAI(api_key=\"\")\n","\n","response = client.fine_tuning.jobs.create(\n","  training_file=\"\",\n","  model=\"gpt-3.5-turbo\",\n","  suffix=\"lawdata01\"\n","  # hyperparameters={\n","  #   \"n_epochs\":2\n","  # }  # the default epoch is 3\n",")\n","\n","job_id = response.id\n","print(\"Job ID:\", response.id)\n","print(\"Status:\", response.status)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":175004,"status":"ok","timestamp":1708332942461,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"2-DskzfIQPEr","outputId":"b4aaaf69-ac4f-4df6-f0c8-a29f1f7158a9"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Retrieving fine-tune job...\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20240219_085248-ftjob-3hu0ac8xCD7YXLr0yeoSkH5Z</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/tw-nlp-law/OpenAI-Fine-Tune/runs/ftjob-3hu0ac8xCD7YXLr0yeoSkH5Z' target=\"_blank\">ftjob-3hu0ac8xCD7YXLr0yeoSkH5Z</a></strong> to <a href='https://wandb.ai/tw-nlp-law/OpenAI-Fine-Tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/tw-nlp-law/OpenAI-Fine-Tune' target=\"_blank\">https://wandb.ai/tw-nlp-law/OpenAI-Fine-Tune</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/tw-nlp-law/OpenAI-Fine-Tune/runs/ftjob-3hu0ac8xCD7YXLr0yeoSkH5Z' target=\"_blank\">https://wandb.ai/tw-nlp-law/OpenAI-Fine-Tune/runs/ftjob-3hu0ac8xCD7YXLr0yeoSkH5Z</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for the OpenAI fine-tuning job to be finished...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fine-tune ftjob-3hu0ac8xCD7YXLr0yeoSkH5Z has failed and will not be logged\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fine-tune ftjob-3hu0ac8xCD7YXLr0yeoSkH5Z has the status \"failed\" and will not be logged\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'ğŸ‰ wandb sync completed successfully'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","from wandb.integration.openai.fine_tuning import WandbLogger  #sync the data\n","\n","# Finetuning logic\n","os.environ[\"OPENAI_API_KEY\"] =\"\"\n","\n","\n","WandbLogger.sync(fine_tune_job_id=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":966,"status":"ok","timestamp":1704179915021,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"fIDIyAQpUAt6","outputId":"cd19caeb-94ea-4e7c-b3f6-9247d7b53904"},"outputs":[{"data":{"text/plain":["SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-lq3HgqDGrQvkao3gyfKzQFQe', created_at=1704179766, level='info', message='Fine-tuning job started', object='fine_tuning.job.event', data=None, type='message'), FineTuningJobEvent(id='ftevent-v0EdVu47HiNR9Y8Qc1bgGhS6', created_at=1704179765, level='info', message='Files validated, moving job to queued state', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-4IH9jeWqJf98My2R3NZopGo0', created_at=1704179764, level='warn', message='File file-0w4HebAfYP54nBaExzTaLORe contains examples greater than the supported context size for model `gpt-3.5-turbo-0613` (4096 tokens)', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-qLnczeTqrohvRKTuqMpHgAG7', created_at=1704179763, level='info', message='Validating training file: file-0w4HebAfYP54nBaExzTaLORe', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-CCbyvTv3dOYhhvYOIX2GRSCr', created_at=1704179763, level='info', message='Created fine-tuning job: ftjob-lhVYdXMCkMKIODq1GjAzThze', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["# æ­¤å€å¡Šç”¨æ–¼å°è¨“ç·´ä»»å‹™é€²è¡Œæ“ä½œ\n","from openai import OpenAI\n","client = OpenAI(api_key=\"\")\n","\n","# åˆ—å‡ºfine tune ä»»å‹™\n","client.fine_tuning.jobs.list(limit=10)\n","\n","# æª¢ç´¢fine tune ç‹€æ…‹\n","client.fine_tuning.jobs.retrieve(\"\")\n","\n","# å–æ¶ˆfinetune\n","# client.fine_tuning.jobs.cancel(\"ftjob-lhVYdXMCkMKIODq1GjAzThze\")\n","\n","# List up to 10 events from a fine-tuning job\n","client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"\", limit=10)\n","\n","# Delete a fine-tuned model (must be an owner of the org the model was created in)\n","# client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:test1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18555,"status":"ok","timestamp":1708059790650,"user":{"displayName":"Shuo Bing Jhang","userId":"16535721502250842542"},"user_tz":-480},"id":"qm-P0PH_--Pk","outputId":"af323cb0-8a4c-4dfd-e0bb-78bc8ecc3d50"},"outputs":[{"name":"stdout","output_type":"stream","text":["è»Šç¦è©²æ€éº¼è¾¦ä¾ç…§æ‰€é€ æˆçš„æå®³ï¼ˆå‹•ç‰©è²¡ç‰©è»Šè¼›å‚·äº¡ç­‰ï¼‰ï¼Œè«‹æ´½è©¢å„ç´šæ³•é™¢ç°¡æ˜“äº‹ä»¶èª¿è§£å®¤ç¨‹åºä¾ç¨‹åºä¾ä»¥ä¸‹æ­¥é©Ÿé€²è¡Œï¼šæ¡ˆä»¶çš„å—ç†ï¼šç”±ç”³è«‹äººæª¢å…·åå†Šç…§ç‰‡ã€åŸè»Šç…§ç‰‡ï¼ˆå…¨è»Šç…§ç‰‡ã€å‚·å®³éƒ¨ä½å„å¼µï¼‰ã€è¢«ç”³è«‹äººä¹‹é§•ç…§è¤‡å°æœ¬æˆ–äº‹å¯¦ç¨±èªªä¹‹ç›¸é—œè­‰æ“šï¼ŒåŠiTypeè¿½è»Šå–®ï¼ˆå¿…è¦æ™‚ï¼‰ã€äº¤é€šäº‹æ•…åŸå› åˆ†ææ›¸ï¼ˆå¿…è¦æ™‚ï¼‰ï¼›æäº¤èª¿è§£ç”³è«‹æ›¸ï¼›æœ¬é™¢æŒ‰æ—¥å—ç†èª¿è§£æ¡ˆä»¶ï¼›ä¸å…·å‚™å‰æ­æ¢æ¬¾è¦å®šè³‡æ ¼ä¹‹ç”³è«‹æ›¸ï¼Œæœ¬é™¢å¾—è¦æ±‚ç”³è«‹äººè£œæ­£ä¹‹ã€‚æœ¬é™¢å¦ä¸äºˆé€²è¡Œæ¡ˆä»¶å—ç†ä¹‹ä¹‹äººèº«å‚·å®³çµ¦ä»˜èªªæ˜æ›¸æˆ–å…¶ä»–æ©Ÿé—œèª¿è§£åŒä¸€ä¹‹è«‹æ±‚ã€‚ä¸äºˆè¤‡å—ç†ã€‚æ—¥æ›†èª¿è§£æœŸæ—¥ä¹‹ç¢ºå®šï¼šæœ¬é™¢è‡ªå—ç†ä¹‹æ¬¡æ—¥èµ·ï¼ŒæœƒåŒç”³è«‹äººã€è¢«ç”³è«‹äººï¼Œå…ˆæœŸç´„å®šæ—¥æ›†èª¿è§£è«‡åˆ¤æœŸæ—¥ä¸€æ¬¡ã€‚è«‡åˆ¤æœŸæ—¥ç¢ºå®šå¾Œï¼Œé‡åˆ°èª¿è§£å“¡çªç™¼å› ç´ ï¼ˆä¾‹ï¼šå—å‚·æ€¥é›£é†«æ²»ã€å®¶åº­ç·Šæ€¥äº‹æ•…ã€å¤©ç½ï¼‰ç­‰å—ä¸å¯æŠ—åŠ›å› ç´ ï¼Œæˆ–å…¶ä»–ç”³è«‹äººã€è¢«ç”³è«‹äººé‡èª¿è§£å“¡ç´„å®šæ—¥æ›†èª¿è§£æ™‚é–“å…ˆå‰ç„¡åŸå› é€šçŸ¥æœ¬é™¢å¾©æ—¥æ›†èª¿è§£ï¼Œè‡´æœ¬é™¢è²è«‹å…ƒæ—¥æ›†èª¿è§£ä¹‹é€šçŸ¥å¤±æ•ˆï¼Œè‡´ç•¶æ—¥æœªèƒ½ä¾æœŸæŠµé”èª¿è§£åœ°é»è€…ï¼Œå…¶æ‰€å—ç†ä¹‹æ°‘äº‹æ—¥æ›†èª¿è§£æ¡ˆä»¶ï¼Œç¬¬ä¸€æ¬¡ç´„å®šèª¿è§£æœŸæ—¥ä¸äºˆè£œç´„ï¼Œé™¤å…¶ä»–ç¤¾æœƒæƒ…ç·’ä¸Šæ›´æœ‰å¹«åŠ©èª¿è§£çµæœèˆ‡ç›®çš„è€…å¤–ï¼Œåœ¨ä¾ä»»ä½•ä¸€æ–¹ä¹‹è«‹æ±‚ï¼Œæˆ–ç¶“æœ¬é™¢ä¹‹æ±‚ç­‰ï¼Œå¾—é©ç•¶è£å®šè®“è«‹æ±‚ä¹‹ä¸€æ–¹æŒ‡å®šæ—¥æ›†èª¿è§£æœŸæ—¥ï¼›è‹¥å·²ç¬¦åˆå¤©ç„¶äººæ°‘å…¬æ­£è¨´è¨Ÿæ³•ç¬¬56æ¢ä¹‹è¦ä»¶è€…äºˆä»¥ç„åŒç¬¬ä¸‰é …å‰æ®µä¹‹è™•åˆ†ã€‚åŸå‰‡ä¸Šæª¢é™„è³‡æ–™è¶Šæ¸…æ¥šè¶Šæœ‰åŠ©ç‚ºä½ å€‘åˆ†è¾¨ç³¾ç´›ä¹‹çµæœã€‚åˆè­°èª¿è§£å› æ•¸æœ‰ç†äº‹å¯¦åŸ‹æ€¨æ°‘çœ¾åŠå„å¼çˆ­åŸ·æ¢°å—ç†æ˜†æ˜å¸‚ç•¶é‹ªè¢«å‘Šé™³å‰‡ç‡Šä¹‹é«˜ç­‰æ³•é™¢æš¨å…¶è¨´è¨ŸåŠéè¨Ÿä»£ç†äººé™¤ä¸­è¯æ°‘åœ‹å¾‹å¸«æˆ–è¨´è¨Ÿä»£ç†äººå¤–ï¼Œä¸å¾—åƒèˆ‡æ¡ˆä»¶åŸ·è¡Œè³‡æ–™ãªã‚Šã‚ã‚Œã‚ã‚Œã¯ã€è‡ªåˆ†ãŸã¡ã¯ã¾ã è‡ªåˆ†ã®æ­£å½“ãªæ¨©åˆ©ã‚’ç¶­æŒã™ã‚‹æ˜¯éã«åçœã—ã¦ã€å¯¾ç«‹ã‚’ç”Ÿã‚€å¯èƒ½æ€§ãŒã‚ã‚‹å ´æ‰€ã«å…¥ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ç§ãŸã¡ã®å¯¾è©±ã«ã¯ã„ã£ãŸã‚“ã€ç§ãŸã¡ã¯æ–°ã—ã„å‡ºä¼šã„ã‚’ã©ã“ã¾ã§ã‚‚æš–ã‹ãç²¾åŠ›çš„ã«ãƒ‡ã‚£ãƒ†ã‚¯ã‚·ãƒ¨ãƒ³ã®ãƒ‡ã‚£ãƒ†ã‚¯ã‚¿ãƒ¼ã€ãƒˆãƒƒãƒ—ã€Rulesã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™.\n"]}],"source":["# ä½¿ç”¨æ¨¡å‹\n","from openai import OpenAI\n","\n","client = OpenAI(organization = '', api_key='')\n","\n","response = client.chat.completions.create(\n","  model=\"\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½å°æ¯å€‹å•é¡Œçµ¦äºˆå®¢è§€å»ºè­°çš„å°ˆæ¥­æ³•å¾‹é¡§å•ã€‚\"},\n","    {\"role\": \"user\", \"content\": \"è»Šç¦è©²æ€éº¼è¾¦\"},\n","  ]\n",")\n","\n","print((response.choices[0].message.content))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4I-4FblT2JU"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
